---
title: Concetti Essenziali
description: Padroneggia i concetti chiave per uso professionale degli LLM - temperature, hallucinations, limiti
sidebar_position: 6
tags: [llm-foundations, temperature, hallucinations, fine-tuning, limiti]
---

# Concetti Essenziali

> â±ï¸ **Durata**: 15 minuti
> ğŸ¯ **Livello**: Base

---

## ğŸ¯ Learning Objectives

Al termine di questa sezione sarai in grado di:

- [ ] Comprendere e applicare il concetto di temperature (creativitÃ  vs precisione)
- [ ] Riconoscere hallucinations e applicare strategie di mitigazione
- [ ] Distinguere fine-tuning da prompt engineering e sapere quando usarli
- [ ] Conoscere knowledge cutoff e altre limitazioni pratiche

---

## ğŸŒ¡ï¸ Temperature: CreativitÃ  vs Precisione

### Cos'Ã¨ Temperature

**Definizione**: Parametro che controlla la **casualitÃ ** (randomness) dell'output LLM.

- **Range**: Tipicamente 0.0 a 1.0 (alcuni modelli fino a 2.0)
- **Default**: ~0.7 nella maggior parte dei modelli

:::tip ğŸ’¡ Analogia: Termostato della CreativitÃ 
- **Temperature Bassa (0.1)** = Output "freddo", deterministico, sicuro
- **Temperature Alta (0.9)** = Output "caldo", creativo, vario
:::

---

### Come Funziona

Ricordi next token prediction?

```
Frase: "Il gatto Ã¨ seduto sul..."

ProbabilitÃ  calcolate:
- "tappeto" â†’ 45%
- "divano" â†’ 30%
- "tavolo" â†’ 15%
- "tetto" â†’ 8%
- altro â†’ 2%
```

**Con Temperature Diversa**:

**Temperature = 0.1** (Bassa - Deterministic):
- Sceglie **quasi sempre** token con massima probabilitÃ 
- "tappeto" â†’ 99% delle volte
- Output ripetibile, prevedibile

**Temperature = 0.7** (Media - Balanced):
- Sceglie in base a probabilitÃ , con varietÃ 
- "tappeto" â†’ ~50%, "divano" â†’ ~35%, "tavolo" â†’ ~15%
- Balance tra coerenza e creativitÃ 

**Temperature = 1.0** (Alta - Creative):
- Distribuisce scelta piÃ¹ uniformemente
- Anche token meno probabili vengono scelti
- Output vario, a volte sorprendente

---

### Temperature Bassa (0.0 - 0.3)

**Caratteristiche**:
- âœ… Output ripetibile (stesso input â†’ stesso output)
- âœ… Preciso, aderente a fatti
- âœ… Conservativo, evita rischi
- âŒ Poco creativo, prevedibile

**Usa Quando**:
- ğŸ“Š **Analisi dati**: Serve precisione
- ğŸ“„ **Documentazione tecnica**: No variazioni
- ğŸ”¢ **Calcoli e logic**: Accuratezza critica
- ğŸ“‹ **Report formali**: Tone consistente

**Esempio PM**:

```
Temperature: 0.1

Prompt: "Calcola effort rimanente: 20 story points totali, 12 completati"

Output: "Effort rimanente: 8 story points.
Percentuale completamento: 60%.
Se velocity media Ã¨ 4 SP/sprint, servono 2 sprint per completare."
```
â†’ Preciso, fattuale, no variazioni

---

### Temperature Media (0.5 - 0.7)

**Caratteristiche**:
- âœ… Balance creativitÃ /precisione
- âœ… Output naturale, conversazionale
- âœ… Varia leggermente ma coerente
- âœ… Default per maggior parte task

**Usa Quando**:
- ğŸ’¬ **Conversazioni generali**
- âœï¸ **Scrittura business standard** (email, report)
- ğŸ¯ **Task balanced** (non serve estrema precisione o creativitÃ )

**Esempio Service Designer**:

```
Temperature: 0.6

Prompt: "Descrivi UX best practice per onboarding mobile"

Output: "Best practices per mobile onboarding:
1. Progressive disclosure - mostra info gradualmente
2. Skip option - permetti utenti esperti di saltare
3. Value-first - spiega benefici prima di chiedere permessi
4. ..."
```
â†’ Informativo ma non robotico

---

### Temperature Alta (0.8 - 1.0+)

**Caratteristiche**:
- âœ… Molto creativo, originale
- âœ… Output vari (stessa query â†’ risultati diversi)
- âœ… Esplora opzioni inaspettate
- âŒ A volte incoerente o off-topic
- âŒ PuÃ² "inventare" piÃ¹ facilmente

**Usa Quando**:
- ğŸ’¡ **Brainstorming**: Vuoi idee diverse
- ğŸ¨ **Content creativo**: Marketing, copywriting
- ğŸ”€ **Esplorare opzioni**: Alternative non convenzionali
- âœ¨ **Naming, titoli**: OriginalitÃ  richiesta

**Esempio PMO - Brainstorming**:

```
Temperature: 0.9

Prompt: "Genera 5 nomi creativi per programma transformation aziendale"

Output (varied ogni volta):
Run 1: "Phoenix Rising", "Quantum Leap", "Catalyst 2025", ...
Run 2: "Metamorphosis", "New Horizons", "Ignition", ...
Run 3: "Evolution Engine", "Breakthrough", "Synergy Force", ...
```
â†’ Ogni run produce idee diverse e creative

---

### Quando NON Puoi Controllare Temperature

**Nota Importante**: Molti tool consumer **non espongono** temperature:

- âŒ ChatGPT web (subscription): usa default (~0.7)
- âŒ Claude web: usa default (~0.7)
- âœ… OpenAI API: controllo completo
- âœ… Anthropic API: controllo completo
- âœ… Google AI Studio: controllo temperature disponibile

**Se non puoi cambiare temperature**: Usa prompt engineering per influenzare creativitÃ 

```
Per output piÃ¹ "freddo" (temperature bassa simulata):
"Rispondi in modo preciso e fattuale, evitando speculazioni."

Per output piÃ¹ "caldo" (temperature alta simulata):
"Genera idee creative e originali, anche inusuali."
```

---

## ğŸ­ Hallucinations: Quando LLM "Inventa"

### Cos'Ã¨ un'Hallucination

**Definizione**: Quando LLM genera informazione **plausibile ma falsa**, presentandola con confidenza.

:::warning âš ï¸ Rischio Principale degli LLM
LLM **non sa quando non sa**. PuÃ² inventare fatti, citazioni, statistiche e sembrar credibile.
:::

---

### Tipi di Hallucinations

**1. Fatti Inventati**

```
âŒ Prompt: "Quando Ã¨ stato fondato Microsoft?"

LLM: "Microsoft Ã¨ stata fondata nel 1976 da Bill Gates e Steve Jobs"

RealtÃ : 1975, Bill Gates e Paul Allen (non Steve Jobs!)
```

**2. Citazioni False**

```
âŒ Prompt: "Citazione famosa di Steve Jobs sulla creativitÃ "

LLM: "Creativity is just connecting things. When you ask creative people how they did something, they feel a little guilty because they didn't really do it, they just saw something." - Steve Jobs

RealtÃ : Potrebbe sembrare plausibile, ma verificare sempre fonte!
```

**3. Statistiche Inventate**

```
âŒ Prompt: "Quanti progetti IT falliscono ogni anno?"

LLM: "Secondo uno studio McKinsey del 2023, il 67.3% dei progetti IT superano il budget del 45% in media"

RealtÃ : Numeri troppo precisi senza fonte = probabile hallucination
```

**4. Riferimenti Inesistenti**

```
âŒ Prompt: "Paper research su AI nel 2024"

LLM: "Vedi il paper 'Advances in Neural Architectures' di Smith et al., pubblicato su Nature AI, Vol 15, 2024"

RealtÃ : Paper potrebbe non esistere!
```

---

### Quando Hallucinations Sono PiÃ¹ Probabili

**Fattori di Rischio**:

1. **Post Knowledge Cutoff**:
   - GPT-4: eventi dopo aprile 2023
   - Claude 3.5: eventi dopo inizio 2024
   - â†’ Alto rischio hallucination

2. **Fatti Ultra-Specifici**:
   - Date precise, numeri esatti
   - Nomi, citazioni letterali
   - â†’ LLM "improvvisa" dettagli

3. **Domini Ultra-Specializzati**:
   - Legge specifica di niche country
   - Medical procedures rare
   - â†’ Training data limitato

4. **Quando "Pressato" a Rispondere**:
   - "Devi darmi una risposta"
   - â†’ LLM inventa piuttosto che ammettere ignoranza

---

### Come Riconoscere Hallucinations

ğŸš© **Red Flags**:

- Numeri/date **troppo specifici** senza fonte
- Citazioni che "suonano bene" ma dubbie
- Confidenza eccessiva su topic oscuro
- Riferimenti a documenti/paper senza link verificabile
- Contraddizioni con conoscenza comune

**Test**:
```
Se LLM dice: "Il 73.2% dei PM usa metodologia XYZ secondo studio ABC 2023"

Ask yourself:
- Ho mai sentito parlare di studio ABC?
- Il numero Ã¨ sospettosamente preciso?
- C'Ã¨ link o fonte verificabile?

â†’ Se no a tutte: probabile hallucination
```

---

### Come Mitigare Hallucinations

âœ… **Strategia 1: Chiedi Fonti Esplicitamente**

```
âŒ Weak: "Quali sono le statistiche sul project failure?"

âœ… Strong: "Quali sono le statistiche sul project failure?
           Cita SOLO fonti verificabili (autore, anno, pubblicazione).
           Se non hai fonte verificabile, dillo esplicitamente."
```

---

âœ… **Strategia 2: "Se Non Sai, Dillo"**

```
Prompt: "Analizza questi dati. Se non hai informazioni sufficienti per
        rispondere con certezza, dichiara esplicitamente 'non ho dati
        sufficienti per...' invece di speculare."
```

---

âœ… **Strategia 3: Fornisci Documenti Accurati**

```
âŒ Risky: "Quali sono i KPI del nostro progetto?"
          â†’ LLM inventa se non sa

âœ… Safe: Upload project charter

"Basandoti SOLO su questo documento, elenca i KPI del progetto.
Se un KPI non Ã¨ menzionato nel documento, non includerlo."
```

---

âœ… **Strategia 4: Fact-Check Critico**

Per informazioni critiche:
- âœ… Verifica con fonte primaria
- âœ… Cross-check con altre fonti
- âœ… Usa web search per info recenti
- âœ… Human review su decisioni importanti

**Regola**: **Mai fidarsi ciecamente** su:
- Fatti medici, legali, finanziari
- Statistiche senza fonte
- Decisioni con impatto alto

---

âœ… **Strategia 5: Abilita Web Search**

Per informazioni post-cutoff o recenti:
- ChatGPT Plus: Abilita "Browse with Bing"
- Claude: Web search (beta feature)
- Gemini: Web search integrato di default

â†’ Riduce hallucination su eventi recenti

---

## ğŸ”§ Fine-Tuning vs Prompt Engineering

### Fine-Tuning

**Cos'Ã¨**: Ri-addestrare modello esistente su dataset specifico

**Come Funziona**:
1. Parti da modello base (GPT-4, Claude)
2. Aggiungi training con tuoi dati
3. Modello "impara" pattern specifici
4. Output nuovo modello customizzato

**Pro**:
- âœ… Performance ottimale per task ultra-specifico
- âœ… PuÃ² imparare terminologia/style aziendale unico
- âœ… Efficiente per volumi enormi di task ripetitivo

**Contro**:
- âŒ Costoso ($$$) - richiede migliaia di esempi
- âŒ Complesso - serve expertise tecnico
- âŒ Tempo - settimane per preparazione + training
- âŒ Manutenzione - devi aggiornare modello quando cambia

**Quando Serve**:
- Hai 10,000+ esempi di task identico
- Performance critica su task specifico
- Budget significativo (â‚¬10K+)
- Team tecnico dedicato

---

### Prompt Engineering

**Cos'Ã¨**: Ottimizzare **input** al modello esistente (no modifica modello)

**Come Funziona**:
1. Scrivi prompt efficace
2. Testa output
3. Itera prompt
4. Usa su modello standard (GPT, Claude)

**Pro**:
- âœ… Immediato - risultati in minuti
- âœ… Flessibile - cambi prompt quando serve
- âœ… No costi extra (oltre subscription/API)
- âœ… No expertise tecnico richiesto

**Contro**:
- âŒ Limiti di ciÃ² che prompt puÃ² ottenere
- âŒ Ogni richiesta "paga" token per prompt lungo
- âŒ Meno preciso di fine-tuning su task ultra-specifico

**Quando Basta** (99% dei casi per business users):
- Task vari (non ultra-ripetitivo identico)
- Budget limitato
- Serve flessibilitÃ 
- No team ML/AI dedicato

---

### Decision Framework

```
Hai budget â‚¬50K+ e team ML?
â”œâ”€ SÃŒ â†’ Considera fine-tuning (se task giustifica)
â””â”€ NO â†’ â†“

Hai 10,000+ esempi di task identico?
â”œâ”€ SÃŒ â†’ Valuta fine-tuning (ROI analysis)
â””â”€ NO â†’ â†“

Task performance critico per business?
â”œâ”€ SÃŒ â†’ Valuta fine-tuning vs prompt engineering avanzato
â””â”€ NO â†’ PROMPT ENGINEERING (start here sempre!)
```

:::tip ğŸ’¡ Regola Pratica
**Inizia SEMPRE con prompt engineering**.

Se dopo aver ottimizzato prompt ottieni:
- &lt;80% accuracy su task critico
- E hai volume enorme (10K+ esempi)
- E budget disponibile

â†’ Allora valuta fine-tuning

Per 99% business users: prompt engineering Ã¨ sufficiente.
:::

---

## ğŸ“… Knowledge Cutoff e Altre Limitazioni

### Knowledge Cutoff

**Cos'Ã¨**: Data limite dei dati di training

| Modello | Knowledge Cutoff |
|---------|------------------|
| GPT-5 | Settembre 2025 |
| Claude Sonnet 4 | Agosto 2025 |
| Gemini 2.5 Pro | Marzo 2025 (web search nativo compensa) |

**Implicazione**:

```
âœ… Prompt: "Cosa Ã¨ successo nella Prima Guerra Mondiale?"
   â†’ LLM risponde accuratamente (ben coperto in training)

âš ï¸ Prompt: "Chi ha vinto elezioni Italia novembre 2025?"
   â†’ GPT-5 (cutoff Set 2025) potrebbe NON SAPERE
   â†’ Usa web search per eventi recentissimi!
```

**Soluzioni**:
1. **Web Search**: Abilita browsing (ChatGPT Plus, Claude, Gemini)
2. **Fornisci Documenti**: Upload articoli/report recenti
3. **Disclaimer**: "Info su eventi pre-[cutoff date] solo"

---

### Altre Limitazioni Importanti

**1. No Esperienza Reale**

LLM non ha:
- Esperienza fisica del mondo
- Emozioni genuine
- Generalmente no memoria tra sessioni

**Esempio**:
```
âŒ "Quanto Ã¨ pesante un laptop da 15 pollici?"

LLM: "Circa 2-3 kg" (dato statistico)

Non ha MAI sollevato un laptop!
```

---

**2. Bias dai Dati di Training**

LLM puÃ² riflettere bias nei dati:
- Bias culturali (training mostly inglese/occidentale)
- Bias professionali
- Stereotipi

**Mitigazione**: Review critico, diversitÃ  input, awareness

---

**3. No Accesso Real-Time (senza tool)**

LLM base non puÃ²:
- âŒ Controllare email
- âŒ Accedere database aziendale
- âŒ Eseguire codice (senza environment)

**Eccezione**: Con tool/plugin/MCP connectors (Giorno 2!)

---

## ğŸ”‘ Key Takeaways

:::tip âœ¨ Punti Chiave da Ricordare

**Temperature**:
- Controlla creativitÃ  vs precisione (0.0 = deterministico, 1.0 = creativo)
- Bassa (0.1-0.3): analisi, docs, precisione
- Media (0.5-0.7): balanced, default
- Alta (0.8-1.0): brainstorming, creativitÃ 
- Molti tool consumer non espongono (usa prompt per influenzare)

**Hallucinations**:
- LLM puÃ² inventare fatti plausibili
- PiÃ¹ probabile su: info recenti, ultra-specifiche, post-cutoff
- Mitigazione: chiedi fonti, "se non sai dillo", fornisci documenti, fact-check critico
- **Mai fidarsi ciecamente** su info critiche (legal, medical, finance)

**Fine-Tuning vs Prompt Engineering**:
- Fine-tuning: custom model, costoso, expertise richiesta
- Prompt Engineering: ottimizza input, immediato, flessibile
- **99% casi**: prompt engineering Ã¨ sufficiente
- Start sempre con prompt engineering

**Knowledge Cutoff**:
- GPT-5: settembre 2025, Claude Sonnet 4: agosto 2025, Gemini 2.5: marzo 2025
- Info post-cutoff o recentissime: usa web search o fornisci documenti
- Sempre verifica date su info time-sensitive

**Limitazioni**:
- No esperienza reale, no emozioni, bias possibili
- No accesso real-time (senza tool)
- No memoria permanente tra sessioni (di default)

**Regola d'Oro**:
- LLM = assistente potente, non oracolo infallibile
- Verifica sempre fatti critici
- Combina LLM + human judgment
- Awareness di limiti = uso efficace

:::

---

## ğŸ”— Risorse Aggiuntive

**Approfondimenti**:
- ğŸ“– [Hallucinations Research](https://www.anthropic.com/index/reducing-hallucinations) - Anthropic research
- ğŸ“– [Temperature Explained](https://platform.openai.com/docs/guides/text-generation) - OpenAI guide
- ğŸ“– [Fine-Tuning Guide](https://platform.openai.com/docs/guides/fine-tuning) - Quando e come

**Best Practices**:
- ğŸ“– [Fact-Checking LLM Output](https://www.anthropic.com/index/fact-checking) - Strategie
- ğŸ“– [Prompt Engineering Guide](https://docs.anthropic.com/claude/docs/prompt-engineering) - Anthropic

---

## â¡ï¸ Prossimi Passi

ğŸ‰ **Congratulazioni!** Hai completato il Modulo 1: LLM Foundations

Ora hai solide basi su:
- âœ… Token e tokenizzazione
- âœ… Architettura LLM (training vs inference)
- âœ… Next token prediction e attention
- âœ… Context window e gestione
- âœ… MultimodalitÃ  e vision
- âœ… Temperature, hallucinations, limiti

**Cosa Fare Ora**:

1. **Review**: Ripassa Key Takeaways di ogni sezione
2. **Pratica**: Applica concetti a un tuo task reale
3. **Break**: Pausa 10 minuti â˜•
4. **Continua**: [Modulo 2 - Prompt Engineering Teoria](../prompt-engineering-teoria) - Tecniche avanzate!

---

:::info ğŸ’¬ Riflessione Finale
**Prima di procedere, chiediti**:
- Quali 3 concetti sono piÃ¹ rilevanti per il tuo lavoro?
- Quale limitation degli LLM ti preoccupa di piÃ¹? Come mitigarla?
- Quale capability (vision, context, etc.) vuoi esplorare subito?

Porta queste riflessioni nel Modulo 2, dove imparerai a sfruttare tutto questo con prompt engineering avanzato!
:::
