---
title: Token - L'Alfabeto degli LLM
description: Comprendi cos'√® un token e perch√© √® fondamentale per usare gli LLM efficacemente
sidebar_position: 1
tags: [llm-foundations, token, ottimizzazione, costi]
---

# Token: l'Alfabeto degli LLM

> ‚è±Ô∏è **Durata**: 15 minuti
> üéØ **Livello**: Base

---

## üéØ Learning Objectives

Al termine di questa sezione sarai in grado di:

- [ ] Spiegare cos'√® un token e come funziona la tokenizzazione
- [ ] Riconoscere come i token impattano costi e context window
- [ ] Applicare tecniche di ottimizzazione dei token nei tuoi prompt

---

## üìö Cos'√® un Token?

**Definizione semplice**: Un **token** √® l'unit√† minima di testo che un LLM pu√≤ processare.

:::tip üí° Analogia Utile
Immagina un LLM come una persona che legge un libro. Per noi umani, l'unit√† minima √® la **lettera**, ma per l'LLM √® il **token**.

Un token pu√≤ essere:
- Una parola intera (`"ciao"` = 1 token)
- Parte di una parola (`"anticostituzionalmente"` = 4+ token)
- Un carattere speciale (`"!"` = 1 token)
- Uno spazio (s√¨, anche gli spazi contano!)
:::

---

## üìñ Come Funziona la Tokenizzazione

La **tokenizzazione** √® il processo di dividere il testo in token.

### Esempi Pratici

**Parole Comuni** (frequenti in training data):
```
"hello" ‚Üí 1 token
"world" ‚Üí 1 token
"ciao" ‚Üí 1 token
```

**Parole Rare o Lunghe**:
```
"antidisestablishmentarianism" ‚Üí 6 token
"elettroencefalografista" ‚Üí 7 token
```

**Spazi e Punteggiatura**:
```
"Hello, world!" ‚Üí 4 token
  ‚îÇ      ‚îÇ   ‚îÇ
  ‚îÇ      ‚îÇ   ‚îî‚îÄ "!" (1 token)
  ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ " world" (1 token - spazio incluso)
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ "Hello" (1 token)
              ‚îî‚îÄ "," (1 token)
```

**Emoji**:
```
"üöÄ" ‚Üí 1 token
"üòÄ" ‚Üí 1 token
"üëçüèº" ‚Üí 2 token (emoji + modificatore tono pelle)
```

**Codice**:
```python
"def hello():" ‚Üí 5 token
# "def", " hello", "(", ")", ":"
```

---

## üåç Differenze tra Lingue

:::warning ‚ö†Ô∏è Italiano usa PI√ô Token dell'Inglese
Gli LLM moderni sono principalmente addestrati su testo inglese. Questo significa:

- **Inglese**: parole comuni = 1 token
- **Italiano**: stessa parola potrebbe essere 2-3 token

**Esempio**:
- `"project"` (inglese) = 1 token
- `"progetto"` (italiano) = 2 token
:::

**Impatto Pratico**:
- Costi API: prompt in italiano costa di pi√π
- Context window: stessa quantit√† di informazioni "pesa" di pi√π in italiano
- Velocit√†: generazione leggermente pi√π lenta

---

## üîß Tool per Visualizzare Token

### OpenAI Tokenizer

Lo strumento online pi√π utile: **[OpenAI Tokenizer](https://platform.openai.com/tokenizer)**

**Come usarlo**:
1. Vai su https://platform.openai.com/tokenizer
2. Incolla il tuo testo
3. Vedi quanti token usa (con colori diversi per ogni token)

üí° **Esercizio Rapido**:
- Vai al tokenizer
- Incolla: "Scrivi un status report del progetto per il cliente"
- Quanti token conta? (Risposta: ~10-12 token)

---

## üí∞ Perch√© i Token Importano

### 1. **Costi API**

Se usi API come GPT-5 o Claude, paghi **per token**:

| Modello | Costo (per 1M token input) | Costo (per 1M token output) |
|---------|---------------------------|----------------------------|
| GPT-5 | $1.25 | $10 |
| Claude Sonnet 4 | $3 (fino 200K), $6 (oltre) | $15 |
| GPT-5 mini | $0.25 | $2 |
| GPT-5 nano | $0.05 | $0.40 |

**Esempio Concreto PM**:
- Status report settimanale: ~800 parole ‚âà 1000 token input + ~500 token output
- Ripetuto 50 volte/anno = 50K input + 25K output token
- Con GPT-5: ~$0.31/anno (trascurabile)
- Ma 10 PM che lo fanno = ~$3/anno (accettabile)

:::tip üí° Quando Preoccuparsi dei Costi
Per utenti individuali con ChatGPT/Claude subscription: **non preoccuparti**.

Quando importa:
- API usage massivo (100+ richieste/giorno)
- Prompt enormi (10K+ token ripetuti)
- Enterprise con molti utenti
:::

---

### 2. **Context Window**

Il **context window** (la "memoria" dell'LLM) √® misurato in token.

| Modello | Context Window |
|---------|----------------|
| GPT-5 | 400,000 token (~300,000 parole) |
| Claude Sonnet 4 | 1,000,000 token (~750,000 parole) |
| Gemini 2.5 Pro | 1,000,000 token (~750,000 parole) |

**Esempio PMO**:
Vuoi analizzare 10 status report contemporaneamente:
- 10 report √ó 800 parole ‚âà 10,000 token
- OK per tutti i modelli moderni (GPT-5: 400K, Claude Sonnet 4: 1M)

‚û°Ô∏è Approfondiremo context window in [Sezione 4 - Contesto](contesto)

---

## üéØ Ottimizzazione Token

### Quando Ottimizzare

‚úÖ **Ottimizza quando**:
- Vicino al limite context window
- Uso API massivo (costi)
- Prompt molto lunghi (>1000 token)

‚ùå **Non ottimizzare quando**:
- Prompt occasionali
- Chiarezza > brevit√†
- Subscription plan (non API pay-per-token)

---

### Tecniche di Ottimizzazione

**1. Rimuovi Ripetizioni**

‚ùå **Prima** (inefficiente):
```
Analizza i rischi del progetto. I rischi del progetto sono molto importanti.
Voglio che tu mi dica quali rischi del progetto sono critici.
```
‚Üí ~25 token

‚úÖ **Dopo** (ottimizzato):
```
Analizza e identifica i rischi critici del progetto.
```
‚Üí ~8 token (risparmio: 70%)

---

**2. Sii Conciso ma Chiaro**

‚ùå **Prima**:
```
Mi piacerebbe se tu potessi gentilmente considerare la possibilit√† di scrivere
per me un riassunto del documento che ho allegato.
```
‚Üí ~20 token

‚úÖ **Dopo**:
```
Riassumi il documento allegato.
```
‚Üí ~5 token

:::warning ‚ö†Ô∏è Non Sacrificare la Chiarezza
```
‚ùå TROPPO conciso: "doc summ"
‚úÖ Giusto equilibrio: "Riassumi il documento allegato"
```
:::

---

**3. Evita Parole Non Necessarie**

**Rimuovi**:
- "per favore", "gentilmente" (LLM non √® permaloso!)
- "vorrei che tu", "mi piacerebbe se"
- Introduzioni lunghe

‚ùå **Prima**:
```
Buongiorno! Spero tu stia bene. Vorrei chiederti se potresti aiutarmi
con un task. Mi piacerebbe se tu potessi analizzare...
```

‚úÖ **Dopo**:
```
Analizza...
```

---

**4. Usa Abbreviazioni (quando chiare)**

**Nel contesto PM/PMO**:
- PM, PMO, BA (se nel tuo dominio)
- Q1, Q2, KPI, ROI
- Attenzione: solo se LLM le conosce dal contesto

‚ùå **Non inventare abbreviazioni oscure**: "STKREP" per status report

---

## üí° Esempi Pratici per Ruolo

### PM - Status Report

‚ùå **Non ottimizzato** (~50 token):
```
Ciao! Mi aiuteresti per favore a scrivere uno status report professionale
per il mio progetto che sto gestendo? Vorrei includere progress, risks e next steps.
Grazie mille!
```

‚úÖ **Ottimizzato** (~15 token):
```
Scrivi status report con: progress, risks, next steps.

[Dati progetto qui]
```

**Risparmio**: 70% token

---

### Service Designer - User Research Synthesis

‚ùå **Non ottimizzato** (~40 token):
```
Ho condotto delle interviste con alcuni utenti e ho raccolto molte note.
Mi piacerebbe se tu potessi aiutarmi a organizzare tutti questi insights
che ho raccolto in modo strutturato.
```

‚úÖ **Ottimizzato** (~12 token):
```
Sintetizza insights dalle interviste utente:

[Note interviste qui]
```

---

### Funzionale - User Stories

‚ùå **Non ottimizzato** (~35 token):
```
Per cortesia, potresti trasformare questi requirements di business che
il cliente mi ha fornito in user stories seguendo il formato agile standard?
```

‚úÖ **Ottimizzato** (~10 token):
```
Trasforma requirements in user stories formato Agile:

[Requirements qui]
```

---

## ‚úèÔ∏è Esercizio Pratico

**Task**: Ottimizza questo prompt

```
Buongiorno! Spero che tu possa aiutarmi con un compito importante.
Ho un meeting molto importante domani mattina con il mio capo e devo
presentare i risultati del progetto. Potresti per favore aiutarmi a
scrivere una presentazione che sia chiara e professionale? Vorrei che
includesse una panoramica del progetto, i risultati ottenuti, le sfide
che abbiamo affrontato e i prossimi passi. Sarebbe fantastico se potessi
rendere tutto molto chiaro e conciso. Grazie mille per il tuo aiuto!
```

**Quanti token?** Usa il [tokenizer](https://platform.openai.com/tokenizer) per scoprirlo.

<details>
<summary>üëâ Clicca per la soluzione ottimizzata</summary>

**Versione Ottimizzata** (~15 token vs ~85 originali):

```
Scrivi presentazione progetto per C-level meeting:
- Overview progetto
- Risultati ottenuti
- Sfide affrontate
- Prossimi passi

Tone: professionale, conciso.
```

**Tecniche applicate**:
1. Rimossi saluti e ringraziamenti
2. Eliminato "vorrei che tu", "mi piacerebbe"
3. Struttura bullet per chiarezza
4. Formato diretto

**Risultato**: Stessa chiarezza, 82% token in meno!

</details>

---

## üîë Key Takeaways

:::tip ‚ú® Punti Chiave da Ricordare

**Cos'√® un Token**:
- Unit√† minima di testo per LLM (‚â† parola)
- Una parola comune = 1 token, parola rara = multipli token

**Perch√© Importa**:
- Determina **costi** API (pay-per-token)
- Consuma **context window** (memoria limitata)
- Influenza **velocit√†** di generazione

**Come Ottimizzare**:
- Rimuovi ripetizioni e parole superflue
- Sii conciso MA chiaro
- Usa strutture (bullet, sezioni) per chiarezza

**Regola d'Oro**:
- Chiarezza > Brevit√†
- Ottimizza solo quando ha senso (API massive, context limits)
- 1 parola inglese ‚âà 1 token | 1 parola italiana ‚âà 1.3 token

:::

---

## üîó Risorse Aggiuntive

**Tool**:
- üîß [OpenAI Tokenizer](https://platform.openai.com/tokenizer) - Visualizza token in real-time
- üîß [Anthropic Token Counter](https://docs.anthropic.com/claude/reference/token-counting) - Per Claude

**Approfondimenti**:
- üìñ [Token Economics](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them) - Guida OpenAI
- üìñ [Glossario - Token](/docs/risorse/glossario#token) - Definizione completa

---

## ‚û°Ô∏è Prossimi Passi

Ora che comprendi i token:

1. **Pratica**: Analizza 2-3 tuoi prompt tipici con il tokenizer
2. **Ottimizza**: Prova a ridurre token del 30-50% mantenendo chiarezza
3. **Continua**: [Anatomia di un LLM](anatomia-llm) - Scopri come LLM usa i token

---

:::info üí¨ Hai Domande?
**Q: Devo sempre contare i token manualmente?**
A: No! Solo quando lavori vicino ai limiti. Per uso normale, non serve.

**Q: Meglio scrivere in inglese per risparmiare token?**
A: Se sei comfortable con l'inglese, s√¨ (risparmio 20-30%). Ma chiarezza conta di pi√π.

**Q: Quanto costa in media un prompt?**
A: Con subscription ChatGPT/Claude: ‚Ç¨0. Con API GPT-4: ~$0.01-0.05 per conversazione tipica.
:::
