# Questionario Pre-Corso Giorno 1 - Content Reference

> üìö **Scopo Documento**: Reference completo del questionario con rationale per ogni domanda
>
> üéØ **Uso**: Backup testuale, comprensione design choices, base per future iterazioni

---

## üìä Overview Questionario

- **Totale Domande**: 25 (17 obbligatorie, 8 opzionali)
- **Tempo Compilazione**: 15-20 minuti
- **Struttura**: 6 sezioni (A-F)
- **Obiettivo**: Valutare livello pre-corso per fine-tuning contenuti Giorno 1

---

## üéØ Obiettivi di Analisi

Il questionario √® progettato per rispondere a queste domande chiave:

1. **Profilo Partecipanti**: Chi sono? Ruoli, seniority, background?
2. **Esperienza LLM**: Quanto/come usano attualmente LLM?
3. **Gap Conoscenza**: Quali concetti fondamentali sono sconosciuti/deboli?
4. **Livello Prompt Engineering**: Quanto sono sofisticati nell'uso di prompt?
5. **Use Cases Prioritari**: Cosa vogliono imparare a fare concretamente?
6. **Auto-Percezione**: Come si valutano? Quali aspettative?

Rispondendo a queste domande, il formatore pu√≤:
- ‚úÖ Adattare velocit√†/profondit√† di ogni modulo
- ‚úÖ Preparare esempi specifici per ruoli presenti
- ‚úÖ Identificare e colmare gap critici
- ‚úÖ Allineare aspettative con contenuti reali
- ‚úÖ Identificare outlier che necessitano attenzione speciale

---

## üìã Sezioni e Rationale

### SEZIONE A: Il Tuo Profilo (5 domande, tutte obbligatorie)

**Obiettivo Sezione**: Comprendere chi sono i partecipanti per contestualizzare esempi e use case

---

#### A1. Nome e Cognome
**Tipo**: Risposta breve
**Obbligatoria**: ‚úÖ

**Rationale**:
- Identificazione per personalizzazione follow-up
- Permette di collegare risposte con persona specifica durante workshop
- Utile per grouping durante esercizi (es: pairing beginner con intermediate)

---

#### A2. Email
**Tipo**: Risposta breve
**Obbligatoria**: ‚úÖ

**Rationale**:
- Contatto per invio materiali pre-work personalizzati
- Invio summary post-workshop
- Backup identificazione (oltre a Google Forms email collection)

---

#### A3. Qual √® il tuo ruolo principale?
**Tipo**: Scelta multipla
**Obbligatoria**: ‚úÖ
**Opzioni**: PM | PMO | Service Designer/UX | Functional/BA | Altro (specificare)

**Rationale**:
- **Critico**: Esempi e use case devono essere role-specific per rilevanza
- Permette di:
  - Preparare case study mirati (es: PM ‚Üí status report, Service Design ‚Üí research synthesis)
  - Bilanciare profondit√† tecnica (Functional pu√≤ tollerare pi√π tech details vs PM)
  - Clustering per esercizi di gruppo (mescolare ruoli per cross-pollination insights)
- Se breakdown mostra 6 PM + 2 PMO ‚Üí enfatizzare project management use case

**Uso Analisi**:
- Conta distribuzione ruoli
- Identifica se gruppo omogeneo o eterogeneo
- Adatta esempi Modulo 1-3 di conseguenza

---

#### A4. Quanti anni di esperienza hai nel tuo ruolo attuale?
**Tipo**: Scelta multipla
**Obbligatoria**: ‚úÖ
**Opzioni**: 0-2 anni | 3-5 anni | 6-10 anni | Oltre 10 anni

**Rationale**:
- **Seniority influenza**:
  - Velocit√† apprendimento (senior = pattern recognition pi√π veloce)
  - Complessit√† use case (senior gestiscono task pi√π strategici)
  - Confidence nel sperimentare (senior pi√π risk-tolerant)
- Esempio: Se classe √® tutta senior (6+ anni) ‚Üí pu√≤ assorbire contenuti pi√π densi, meno step-by-step

**Uso Analisi**:
- Calcola esperienza media
- Se molto junior (0-2 anni dominante) ‚Üí rallentare, pi√π hand-holding
- Se molto senior (10+ dominante) ‚Üí accelerare teoria, focus su advanced techniques

---

#### A5. Il tuo background formativo √® prevalentemente STEM?
**Tipo**: Scelta multipla
**Obbligatoria**: ‚úÖ
**Opzioni**: S√¨ STEM | No umanistico/economico/altro | Background misto

**Rationale**:
- **Background STEM**:
  - Maggiore comfort con concetti tecnici (architettura LLM, token, algoritmi)
  - Pu√≤ tollerare pi√π dettagli sul "come funziona" senza sentirsi sopraffatto
- **Background Non-STEM**:
  - Necessita analogie pi√π accessibili, meno tecnicismi
  - Focus su "cosa fa" e "come usare" piuttosto che "come funziona internamente"
- Target workshop √® non-STEM, ma se emergono molti STEM ‚Üí pu√≤ essere opportunit√† per pi√π profondit√†

**Uso Analisi**:
- Se >70% non-STEM (atteso) ‚Üí conferma approccio no-jargon, analogie business
- Se 30%+ STEM ‚Üí pu√≤ aggiungere "tech deep-dive" opzionali in appendice slide

---

### SEZIONE B: La Tua Esperienza con LLM (4 domande)

**Obiettivo Sezione**: Comprendere uso attuale, familiarit√† con strumenti, pattern di utilizzo

---

#### B1. Con quale frequenza usi attualmente strumenti LLM?
**Tipo**: Scelta multipla
**Obbligatoria**: ‚úÖ
**Opzioni**: Mai/quasi mai | Occasionalmente (1-3/mese) | Regolarmente (1-3/settimana) | Frequentemente (quasi tutti i giorni) | Costantemente (pi√π volte/giorno)

**Rationale**:
- **Indicatore chiave livello pratico**:
  - "Mai" ‚Üí necessita intro base, walkthrough UI Claude
  - "Costantemente" ‚Üí gi√† power user, cerca optimization
- Media classe determina se workshop parte da zero o assume baseline
- Dispersione indica eterogeneit√† (problematico se troppo ampia)

**Uso Analisi**:
- Calcola % per ogni categoria
- Se >60% "Mai/Occasionalmente" ‚Üí classe beginner, rallentare Modulo 1
- Se >60% "Regolarmente/Frequentemente" ‚Üí classe intermediate, accelerare teoria, pi√π advanced techniques
- Red Flag: Se 2 "Mai" + 6 "Costantemente" ‚Üí gestire eterogeneit√† con track parallele

---

#### B2. Quali strumenti LLM hai usato almeno una volta?
**Tipo**: Caselle controllo (selezione multipla)
**Obbligatoria**: ‚úÖ
**Opzioni**: ChatGPT | Claude | Gemini | Microsoft Copilot | Altri (specificare) | Nessuno

**Rationale**:
- **Familiarit√† con Claude** (focus workshop):
  - Se >50% non hanno mai usato Claude ‚Üí necessita onboarding UI Giorno 1 inizio
  - Se tutti hanno usato ChatGPT ma non Claude ‚Üí evidenziare differenze chiave
- Strumento dominante influenza frame of reference (es: ChatGPT users abituati a certo stile risposta)

**Uso Analisi**:
- % per ogni tool
- Claude familiarity: se <30% ‚Üí aggiungi 10 min "Claude walkthrough" pre-Modulo 1
- Se Microsoft Copilot alto ‚Üí alcuni hanno esposizione enterprise AI (policy, governance)

---

#### B3. Per quali attivit√† usi principalmente gli LLM?
**Tipo**: Caselle controllo
**Obbligatoria**: ‚úÖ
**Opzioni**: Email/comunicazioni | Riassunti documenti | Brainstorming | Analisi dati | Documentazione | Troubleshooting | Imparare concetti | Coding | Altro | Non li uso ancora

**Rationale**:
- **Identifica pattern uso attuale**:
  - Aiuta capire se uso √® superficial (email, riassunti) vs deep (analisi, coding)
  - Use case attuali diventano starting point per esempi avanzati
- Top 3 attivit√† ‚Üí devono essere coperte in Modulo 2-3 con tecniche avanzate

**Uso Analisi**:
- Ranking attivit√† per frequenza
- "Documentazione" molto citato ‚Üí enfatizzare template Esercizio 2
- "Brainstorming" alto ‚Üí mostrare Chain-of-Thought per ideation strutturata
- "Coding" presente ma non dominante ‚Üí tranquillizzare che Giorno 1 √® no-code

---

#### B4. Condividi un esempio di prompt che usi tipicamente
**Tipo**: Paragrafo (testo lungo)
**Obbligatoria**: ‚ùå Opzionale

**Rationale**:
- **Domanda pi√π preziosa per assessment livello**:
  - Vedere prompt reali rivela sofisticazione meglio di auto-valutazione
  - Esempi possono diventare "before/after" case study durante Modulo 2
- Pattern comuni identificabili:
  - Prompt "command" basic: "Riassumi questo" ‚Üí beginner
  - Prompt con contesto: "Sei PM, analizza rischi considerando..." ‚Üí intermediate
  - Prompt con framework: "Usando RACE, genera..." ‚Üí advanced
- Opzionale per non intimidire (alcuni potrebbero sentirsi giudicati)

**Uso Analisi**:
- Analizza 5-8 esempi pi√π rappresentativi
- Identifica pattern (lunghezza, struttura, specificit√†)
- Livello medio prompt ‚Üí calibra aspettative Modulo 2
- Quote anonimizzate diventano esempi durante workshop (con permesso)

---

### SEZIONE C: Conoscenze Fondamentali LLM (6 domande)

**Obiettivo Sezione**: Misurare familiarit√† con concetti chiave che saranno coperti nel Modulo 1

**Scala Comune**: 1-5 (1=Mai sentito, 5=Esperto potrei spiegare ad altri)

**Rationale Scala**:
- Likert 1-5 permette analisi quantitativa (media, distribuzione)
- Identifica concetti completamente sconosciuti (score 1-2) vs familiari (4-5)
- Guida timing: concetti con media <2.5 necessitano pi√π tempo

---

#### C1. Token (l'unit√† base di testo per gli LLM)
**Tipo**: Scala lineare 1-5
**Obbligatoria**: ‚úÖ

**Rationale**:
- **Concetto fondamentale critico**: tutto il resto si basa su comprensione token
- Se score basso ‚Üí rallentare spiegazione, demo interattiva tokenizer
- Se score alto ‚Üí sintesi veloce, focus su ottimizzazione pratica
- Token √® spesso misconosciuto anche da regular users ChatGPT

**Uso Analisi**:
- Media classe su questo concetto
- Se <2.5 ‚Üí dedicare 15-18 min invece di 10 min standard
- Preparare demo live con OpenAI tokenizer su esempi partecipanti

---

#### C2. Context Window (la "memoria di lavoro" dell'LLM)
**Tipo**: Scala lineare 1-5
**Obbligatoria**: ‚úÖ

**Rationale**:
- Essenziale per capire limiti e gestione conversazioni lunghe
- Influenza best practices (quando caricare file vs copiare testo, quando nuova chat)
- Molti users casuali non sanno che LLM ha "memoria limitata"

**Uso Analisi**:
- Se score basso + domanda B1 mostra uso frequente ‚Üí opportunit√† "aha moment" (usano senza capire limiti)
- Se score alto ‚Üí focus su strategie avanzate (Projects, chunking)

---

#### C3. Temperature (controllo creativit√†/casualit√† nelle risposte)
**Tipo**: Scala lineare 1-5
**Obbligatoria**: ‚úÖ

**Rationale**:
- Concetto meno critico per beginner (molti tool non espongono parameter)
- Utile per advanced users che vogliono controllo fine
- Score tipicamente pi√π basso di altri (meno discusso online)

**Uso Analisi**:
- Se score molto basso (<2.0) ‚Üí pu√≤ essere skipped o sintesi rapida
- Se score moderato (2.5-3.5) ‚Üí spiegazione con esempi (quando usare low vs high)

---

#### C4. Hallucinations (quando LLM "inventa" informazioni)
**Tipo**: Scala lineare 1-5
**Obbligatoria**: ‚úÖ

**Rationale**:
- **Critico per uso professionale sicuro**
- Anche chi non conosce termine, probabilmente ha sperimentato fenomeno
- Deve essere enfatizzato se classe user√† LLM per deliverable critici

**Uso Analisi**:
- Se score basso ‚Üí dedicare tempo extra, esempi concreti, strategie mitigation
- Se score alto ‚Üí quick recap + focus su advanced mitigation (citations, constrained generation)

---

#### C5. Training vs Inference (differenza tra fase di apprendimento e uso del modello)
**Tipo**: Scala lineare 1-5
**Obbligatoria**: ‚úÖ

**Rationale**:
- Aiuta capire cosa LLM pu√≤/non pu√≤ fare
- Previene misconcezioni ("LLM impara da me" ‚Üí no, √® inference)
- Pi√π concettuale, meno immediatamente pratico

**Uso Analisi**:
- Se score molto basso ‚Üí semplificare spiegazione con analogia (universit√† vs esame)
- Se score alto ‚Üí sintesi veloce

---

#### C6. Multimodalit√† (capacit√† LLM di lavorare con immagini, non solo testo)
**Tipo**: Scala lineare 1-5
**Obbligatoria**: ‚úÖ

**Rationale**:
- Feature potente ma underutilized
- Se score basso ‚Üí grande opportunit√† "wow moment" con demo live
- Use case pratici (screenshot Gantt, whiteboard foto, dashboard)

**Uso Analisi**:
- Se score basso + domanda B3 non include "analisi immagini" ‚Üí preparare demo impattante
- Se score alto ‚Üí focus su use case avanzati (document analysis multi-page)

---

### SEZIONE D: Prompt Engineering (4 domande)

**Obiettivo Sezione**: Valutare sofisticazione attuale nell'arte di scrivere prompt

---

#### D1. Hai mai sentito parlare di "Prompt Engineering"?
**Tipo**: Scelta multipla
**Obbligatoria**: ‚úÖ
**Opzioni**: No, prima volta | S√¨ sentito ma mai applicato | S√¨, provato tecniche base | S√¨, applico con framework specifici

**Rationale**:
- **Baseline awareness del campo**
- "No, prima volta" ‚Üí Modulo 2 parte da zero, enfatizzare value proposition
- "Applico framework" ‚Üí pu√≤ accelerare, focus su framework avanzati (meta-prompting)

**Uso Analisi**:
- % per categoria
- Se >70% "Mai sentito/sentito ma non applicato" ‚Üí classe beginner PE, approach didattico step-by-step
- Se mix ‚Üí considerare quick recap basics + deeper dive tecniche avanzate

---

#### D2. Conosci/usi framework per strutturare prompt? (es: RACE, Chain-of-Thought, Few-Shot)
**Tipo**: Scala lineare 1-5
**Obbligatoria**: ‚úÖ
**Range**: 1 (Mai sentito) - 5 (Li uso regolarmente)

**Rationale**:
- **Core skill per Modulo 2**
- Framework sono il "salto di qualit√†" da casual a power user
- Score qui predice quanto tempo serve su RACE, CoT, Few-Shot

**Uso Analisi**:
- Media score
- Se <2.0 ‚Üí maggior parte Modulo 2 su framework base (RACE, CoT, Few-Shot)
- Se >3.5 ‚Üí pu√≤ aggiungere framework avanzati (ReAct, Tree-of-Thought) in appendice

---

#### D3. Quanto spesso ottimizzi/raffini un prompt che non ha dato buoni risultati?
**Tipo**: Scelta multipla
**Obbligatoria**: ‚úÖ
**Opzioni**: Mai, accetto primo risultato | Raramente | A volte (1-2 iterazioni) | Spesso (3+ tentativi) | Sistematicamente con tecniche debugging

**Rationale**:
- **Mindset indicatore**:
  - "Mai/Raramente" ‚Üí necessita convincimento del valore iterazione
  - "Sistematicamente" ‚Üí gi√† ha debugging workflow, pu√≤ essere enhanced
- Iterazione √® skill critica per prompt engineering efficace

**Uso Analisi**:
- % per categoria
- Se "Mai/Raramente" dominante ‚Üí enfatizzare Modulo 2.7 (Debugging), mostrare ROI iterazione
- Se "Spesso/Sistematicamente" ‚Üí fornire framework strutturato (checklist debugging) per efficiency

---

#### D4. Hai mai creato template/prompt riutilizzabili per task ricorrenti?
**Tipo**: Scelta multipla
**Obbligatoria**: ‚úÖ
**Opzioni**: No, sempre nuovi | Pensato ma mai fatto | S√¨, 1-2 template | S√¨, 3-5 template | S√¨, libreria estesa 5+

**Rationale**:
- **Applicazione pratica avanzata**
- Template = efficiency massima per task ripetitivi
- Esercizio 2 (Modulo 3) si basa su creazione template ‚Üí questa domanda indica quanto tempo serve

**Uso Analisi**:
- % con template esistenti
- Se "No/Pensato ma mai fatto" >70% ‚Üí enfatizzare value durante Modulo 2, dedicare pi√π tempo Esercizio 2
- Se alcuni hanno gi√† librerie ‚Üí possono condividere esempi durante workshop (peer learning)

---

### SEZIONE E: Use Cases e Priorit√† (3 domande)

**Obiettivo Sezione**: Identificare cosa vogliono imparare a fare concretamente (guida esempi e esercizi)

---

#### E1. Quali task del tuo lavoro quotidiano vorresti automatizzare/ottimizzare con LLM? (elenco prioritario)
**Tipo**: Paragrafo
**Obbligatoria**: ‚úÖ

**Rationale**:
- **Domanda pi√π actionable per personalizzazione**
- Risposte dirette diventano:
  - Esempi durante Modulo 2 (RACE per status report, Few-Shot per requirements)
  - Focus Esercizio 2 (template per top use case)
  - Case study per Modulo 3
- Partecipanti pi√π engaged se vedono loro use case risolti

**Uso Analisi**:
- Aggregare risposte, identificare top 5 use case citati
- Breakdown per ruolo (PM vs PMO vs Service Design vs Functional)
- Preparare 1 template pre-fatto per use case #1 come demo Modulo 2

---

#### E2. Qual √® il principale ostacolo che ti impedisce di usare LLM pi√π efficacemente?
**Tipo**: Scelta multipla
**Obbligatoria**: ‚úÖ
**Opzioni**: Non so scrivere prompt efficaci | Risultati troppo generici | Non conosco funzionalit√† avanzate | Manca tempo | Policy aziendali | Non vedo use case | Altro

**Rationale**:
- **Identifica pain point da addressare**
- Ostacolo #1 deve essere risolto da workshop (altrimenti non serve)
- "Non so scrivere prompt" ‚Üí focus Modulo 2
- "Risultati generici" ‚Üí enfatizzare specificit√† (contesto, formato, few-shot)
- "Policy aziendali" ‚Üí discussione governance, privacy durante Q&A

**Uso Analisi**:
- Top ostacolo citato
- Adatta enfasi moduli per risolverlo
- Se "Policy aziendali" alto ‚Üí aggiungi slide best practice privacy/compliance

---

#### E3. C'√® un task specifico o tipo di documento che vorresti imparare a generare/ottimizzare?
**Tipo**: Paragrafo
**Obbligatoria**: ‚ùå Opzionale

**Rationale**:
- Opzionale per non duplicare E1, ma permette focus su output specifico
- Alcuni potrebbero citare formato particolare (user story, test case, journey map)
- Diventa esempio concreto per Few-Shot learning

**Uso Analisi**:
- Identifica formati specifici citati
- Se "user stories" citato 3+ volte ‚Üí prepara template RACE per requirements‚Üíuser stories
- Quote esempi specifici durante Modulo 2

---

### SEZIONE F: Auto-Valutazione e Aspettative (4 domande)

**Obiettivo Sezione**: Comprendere percezione di s√©, confidence, aspettative (allineare con realt√† workshop)

---

#### F1. Come valuti il tuo livello attuale nell'uso di LLM?
**Tipo**: Scelta multipla
**Obbligatoria**: ‚úÖ
**Opzioni**: Principiante assoluto | Principiante consapevole | Intermedio | Avanzato | Esperto

**Rationale**:
- **Auto-percezione vs realt√†** (cross-check con C1-C6, D1-D4)
- Alcune persone overestimate/underestimate ‚Üí identifica Dunning-Kruger
- Distribuzione cluster indica eterogeneit√†

**Uso Analisi**:
- % per livello
- Confronta con score oggettivo domande C/D
- Red Flag: se "Avanzato" ma C1-C6 media <2.5 ‚Üí overconfident, gestire aspettative
- Se "Principiante" ma C/D score alto ‚Üí underconfident, rassicurare

---

#### F2. Quanto ti senti sicuro/a nell'usare LLM per task lavorativi critici (es: documenti per C-level)?
**Tipo**: Scala lineare 1-5
**Obbligatoria**: ‚úÖ
**Range**: 1 (Per nulla sicuro, sempre verifica) - 5 (Molto sicuro, minima revisione)

**Rationale**:
- **Confidence √® diverso da competenza**
- Low confidence anche con skill ‚Üí necessita reassurance, esempi success case
- High confidence con low skill ‚Üí risk, enfatizzare hallucinations, verification

**Uso Analisi**:
- Media confidence
- Confronta con livello skill (C/D average)
- Se confidence < skill ‚Üí rassicurare, mostrare best practice che danno sicurezza
- Se confidence > skill ‚Üí enfatizzare limiti, verification workflows

---

#### F3. Qual √® la tua aspettativa principale dal Giorno 1 del workshop?
**Tipo**: Paragrafo
**Obbligatoria**: ‚úÖ

**Rationale**:
- **Critico per alignment aspettative**
- Aspettative non allineate ‚Üí insoddisfazione anche se contenuto ottimo
- Identifica misconcezioni (es: "imparo a programmare" ‚Üí no, Giorno 1 √® no-code)
- Temi ricorrenti diventano talking points introduzione Giorno 1

**Uso Analisi**:
- Cluster aspettative in categorie (skill tecnici, use case specifici, mindset change, etc.)
- Red Flag: aspettative fuori scope ‚Üí email pre-workshop per allineare
- Quote aspettative comuni in intro Giorno 1 ("So che molti vogliono...")

---

#### F4. C'√® qualcosa di specifico che vorresti NON fosse coperto?
**Tipo**: Paragrafo
**Obbligatoria**: ‚ùå Opzionale

**Rationale**:
- Evitare perdere tempo su contenuti non rilevanti
- Se 3+ citano "troppo coding/tecnico" ‚Üí conferma approccio no-code
- Se alcuni "gi√† conosco bene X" ‚Üí pu√≤ essere sintetizzato o skipped

**Uso Analisi**:
- Identifica topic da evitare/sintetizzare
- Adatta contenuto per eliminare ridondanze

---

## üìä Analisi Aggregata: Come Usare i Dati

### Metriche Chiave da Calcolare

1. **Profilo Classe**:
   - N partecipanti per ruolo
   - Esperienza media anni
   - % STEM vs non-STEM
   - Strumento LLM dominante

2. **Livello LLM**:
   - Frequenza uso media (convertire a scala 1-5)
   - Score medio conoscenze fondamentali (C1-C6)
   - Score medio prompt engineering (D2, D4)
   - Livello auto-valutato (F1) vs oggettivo

3. **Needs & Gaps**:
   - Top 3 concetti con score pi√π basso (C1-C6)
   - Top 3 use case citati (E1)
   - Ostacolo principale (E2)

4. **Eterogeneit√†**:
   - Range score (min-max) su C1-C6
   - Dispersione livello auto-valutato (F1)
   - Identifica outlier (1-2 molto avanzati o molto beginner)

### Decision Tree per Fine-Tuning

```
IF media C1-C6 < 2.5 THEN
  ‚Üí Classe Beginner Foundations
  ‚Üí Rallentare Modulo 1 (+15 min)
  ‚Üí Aggiungere demo interattive
  ‚Üí Semplificare terminologia

ELSE IF media C1-C6 > 3.5 THEN
  ‚Üí Classe Intermediate/Advanced
  ‚Üí Sintesi rapida Modulo 1 (-10 min)
  ‚Üí Pi√π tempo Modulo 2 tecniche avanzate (+10 min)

IF media D2 < 2.0 THEN
  ‚Üí Prompt Engineering beginner
  ‚Üí Focus su framework base (RACE, Few-Shot, CoT)
  ‚Üí Tempo extra Esercizio 2 (template creation)

ELSE IF media D2 > 3.5 THEN
  ‚Üí Prompt Engineering intermediate+
  ‚Üí Aggiungere Meta-Prompting, advanced debugging
  ‚Üí Challenge exercises

IF eterogeneit√† alta (range C1-C6 > 3 punti) THEN
  ‚Üí Red Flag: gestire disparit√†
  ‚Üí Considerare track parallele Esercizio 3
  ‚Üí Pairing beginner-intermediate per peer learning

IF use case E1 convergenti (3+ citano stesso task) THEN
  ‚Üí Preparare template specifico pre-fatto
  ‚Üí Usare come case study Modulo 2

IF aspettative F3 fuori scope (>30%) THEN
  ‚Üí Email pre-workshop per allineare
  ‚Üí Chiarire cosa √®/non √® coperto Giorno 1
```

---

## üéØ Esempio Analisi Completa (Scenario Ipotetico)

### Input Dati (8 partecipanti)

**Profilo**:
- Ruoli: 4 PM, 2 PMO, 1 Service Design, 1 Functional
- Esperienza: media 6.5 anni (range 3-12)
- Background: 7 non-STEM, 1 STEM

**Esperienza LLM**:
- Frequenza: 3 "Regolarmente", 4 "Occasionalmente", 1 "Mai"
- Strumenti: 7 ChatGPT, 2 Claude, 0 Gemini
- Uso: Top 3 ‚Üí Email (7), Riassunti (6), Brainstorming (5)

**Conoscenze Fondamentali (media 1-5)**:
- Token: 1.9
- Context: 2.1
- Temperature: 1.5
- Hallucinations: 3.2
- Training vs Inference: 1.8
- Multimodalit√†: 2.7

**Prompt Engineering**:
- Sentito PE: 2 "No", 4 "Sentito ma non applicato", 2 "Tecniche base"
- Framework: media 1.6
- Iterazione: 5 "A volte", 2 "Raramente", 1 "Spesso"
- Template: 6 "No", 1 "Pensato ma mai fatto", 1 "1-2 template"

**Use Cases Top (E1)**:
1. Status report settimanali (5 citazioni)
2. Meeting notes ‚Üí action items (4)
3. Risk analysis (3)
4. Requirements ‚Üí user stories (2)

**Ostacoli (E2)**:
- Non so scrivere prompt efficaci: 5
- Risultati troppo generici: 2
- Manca tempo: 1

**Auto-Valutazione**:
- Livello: 1 "Principiante assoluto", 5 "Principiante consapevole", 2 "Intermedio"
- Confidence: media 2.4/5

### Output Analisi ‚Üí Raccomandazioni

**Profilo Classe**: Beginner consapevole, mix PM-PMO dominante, non-STEM, uso occasionale-regolare ChatGPT

**Top 3 Gap**:
1. Temperature (1.5) ‚Üí pu√≤ essere sintetizzato, non critico
2. Training vs Inference (1.8) ‚Üí serve analogia semplice, max 10 min
3. Token (1.9) ‚Üí **CRITICO**, dedicare 18 min con demo live tokenizer

**Raccomandazioni Modulo 1** (75 min):
- Token: 18 min (vs 12 standard) ‚Üí demo interattiva, esempi status report
- Context: 14 min ‚Üí enfatizzare gestione documenti lunghi (use case relevante)
- Temperature: 6 min (vs 10 standard) ‚Üí sintesi rapida, "nice to know"
- Hallucinations: 12 min ‚Üí gi√† discreto (3.2), quick recap + mitigation
- Multimodalit√†: 15 min ‚Üí demo screenshot‚Üítext, use case meeting notes da whiteboard
- Resto: 10 min

**Raccomandazioni Modulo 2** (90 min):
- RACE: 25 min ‚Üí foundation critica, classe beginner PE
- Few-Shot: 20 min ‚Üí use case status report con template esempio
- CoT: 15 min ‚Üí use case risk analysis (citato)
- Role-Based: 12 min
- Debugging: 15 min ‚Üí ostacolo #1 √® "prompt inefficaci"
- Meta-Prompting: 3 min sintesi (vs 10 standard) ‚Üí troppo avanzato per beginner

**Raccomandazioni Modulo 3** (75 min):
- Esercizio 1: 25 min ‚Üí usa prompt reali condivisi (domanda B4)
- Esercizio 2: 40 min (vs 30 standard) ‚Üí focus su status report template, meeting notes‚Üíaction items
- Peer Review: 10 min

**Template da Preparare**:
1. RACE template per weekly status report (citato 5 volte)
2. Few-Shot template meeting notes ‚Üí action items (citato 4 volte)

**Comunicazione Pre-Workshop**:
- Email a 1 partecipante "Mai" usato LLM ‚Üí inviare walkthrough Claude 10 min
- Email generale: chiarire Giorno 1 √® no-code (1 STEM potrebbe aspettarsi tecnicismi)

**Red Flags**:
- Nessun red flag critico, classe relativamente omogenea
- Monitor 1 partecipante "Mai" durante Modulo 1 (possibile difficolt√† seguire ritmo)

---

## ‚úÖ Checklist Validazione Questionario

Prima di distribuire, verifica:

- [ ] Tutte 25 domande presenti
- [ ] Domande obbligatorie marcate (17 totali)
- [ ] Scale 1-5 hanno labels corrette (Mai sentito ‚Üí Esperto)
- [ ] Opzioni scelta multipla coprono tutti casi (con "Altro" dove appropriato)
- [ ] Placeholder text chiari per domande aperte
- [ ] Nessuna domanda duplicata o ridondante
- [ ] Timing compilazione realistico (15-20 min con 25 domande)
- [ ] Linguaggio accessibile per non-STEM
- [ ] Nessuna domanda che richiede conoscenza tecnica pregressa

---

**Fine Reference Document**
